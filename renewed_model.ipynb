{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee99809",
   "metadata": {},
   "source": [
    "## Live Predictions for given input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec1833",
   "metadata": {},
   "source": [
    "#### model takes required params in required format. input columns list looks like this:\n",
    "#####                  [\"uprn\", \"latitude\", \"longitude\", \"property_type\", \"number_of_bedrooms\"]\n",
    "\n",
    "\n",
    "#### after finishing running, it generates output data for individual property including time series (truth and forecast values and normalized values as well . outpul columns list looks like this: \n",
    "#####                [\"uprn\",\"property_type\", 'pred', 'area_code', 'district_code' ,'last_transaction_price', 'last_transaction_date',\" target_ts\", \"forecast\",  \"normalized_target_ts\",\"normalized_forecast\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1fcf4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import h3\n",
    "from prophet import Prophet\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime \n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "from IPython.display import clear_output\n",
    "# import catboost as cb\n",
    "from awswrangler.athena import read_sql_query\n",
    "import quantstats as qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70604c",
   "metadata": {},
   "source": [
    "### Here you can change date parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e4291945",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_TIME = \"2022-04-01\"\n",
    "TARGET_TIME_12m = \"2022-04-01\"\n",
    "TARGET_TIME_24m = \"2023-04-01\"\n",
    "TRAINING_MONTHS = 48\n",
    "PREDICTION_MONTHS = 24+1\n",
    "LAST_TRANSACTION_DATE_LOWER_BOUND = datetime.datetime.strptime('2019-01-01', \"%Y-%m-%d\").date()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5973bc4e",
   "metadata": {},
   "source": [
    "## Training data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76924711",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_price_asked = pd.read_parquet(\"s3://francesco-magic-corner/predictive_model/comparables/listings/\")\n",
    "source_price_asked = source_price_asked.loc[source_price_asked[\"date\"]>pd.to_datetime(\"2012-01-01\")].reset_index(drop=True)\n",
    "source_price_asked[\"bedrooms\"] = source_price_asked[\"rooms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bbf6f9",
   "metadata": {},
   "source": [
    "## input data with required params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b43a57",
   "metadata": {},
   "source": [
    "#### input data format is strictly determined, in case of mismatch, error message is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0b174e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = [\"uprn\", \"latitude\", \"longitude\", \"property_type\", \"number_of_bedrooms\"]\n",
    "input_df = pd.read_csv(\"input_data.csv\").fillna('')\n",
    "input_columns = input_df.columns\n",
    "for col in required_columns:\n",
    "    if col not in input_columns:\n",
    "        raise ValueError('incorrect input format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f781ef",
   "metadata": {},
   "source": [
    "## Merging input data with data stored in Athena tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede5422",
   "metadata": {},
   "source": [
    "#### here we aim to get last transaction information from our db for performing calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b178b548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "merged_df = input_df\n",
    "dfs_list = []\n",
    "uprns = input_df[\"uprn\"]\n",
    "for uprn in uprns:\n",
    "    query = (\n",
    "            f\"SELECT uprn,latitude,longitude,area_code,district_code,postcode,\\\n",
    "            number_habitable_rooms,price,date_of_transfer, property_type FROM lr_epc_matched WHERE uprn = {uprn}\"\n",
    "        )\n",
    "    dfs = read_sql_query(\n",
    "        sql=query,\n",
    "        database=\"realyse-data-pipelines-master-builds\",\n",
    "        ctas_approach=True,\n",
    "        chunksize=100_000,\n",
    "        max_cache_seconds=86400,\n",
    "    )\n",
    "    for df in dfs:\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            continue\n",
    "        dfs_list.append(df)\n",
    "    \n",
    "    \n",
    "# uprns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0afd2867",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = dfs_list[0]\n",
    "for i in range (len(dfs_list)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    res_df = pd.concat([res_df,dfs_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "764d9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df[res_df[\"date_of_transfer\"]>=datetime.datetime.strptime('2019-01-01', \"%Y-%m-%d\").date()]\n",
    "res_df = res_df.rename(columns={'price': 'last_transaction_price', 'date_of_transfer': 'last_transaction_date'})\n",
    "res_df = res_df[res_df[\"last_transaction_date\"]>=LAST_TRANSACTION_DATE_LOWER_BOUND]\n",
    "res_df = pd.merge(res_df, input_df, how='inner',left_on=['uprn','property_type'],right_on=['uprn','property_type' ])\n",
    "res_df = res_df.drop([\"latitude_y\", \"longitude_y\"],axis=1)\n",
    "merged_df = res_df.rename(columns={'latitude_x': 'latitude', 'longitude_x': 'longitude'})\n",
    "merged_df[\"pred\"] = merged_df[\"number_of_bedrooms\"]\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765f4c5",
   "metadata": {},
   "source": [
    "## class for suppressing stdout "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34897e3",
   "metadata": {},
   "source": [
    "#### the class is responsible for avoiding printing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8b86f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class suppress_stdout_stderr(object):\n",
    "    '''\n",
    "    A context manager for doing a \"deep suppression\" of stdout and stderr in\n",
    "    Python, i.e. will suppress all print, even if the print originates in a\n",
    "    compiled C/Fortran sub-function.\n",
    "       This will not suppress raised exceptions, since exceptions are printed\n",
    "    to stderr just before a script exits, and after the context manager has\n",
    "    exited (at least, I think that is why it lets exceptions through).\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Open a pair of null files\n",
    "        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]\n",
    "        # Save the actual stdout (1) and stderr (2) file descriptors.\n",
    "        self.save_fds = (os.dup(1), os.dup(2))\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Assign the null pointers to stdout and stderr.\n",
    "        os.dup2(self.null_fds[0], 1)\n",
    "        os.dup2(self.null_fds[1], 2)\n",
    "\n",
    "    def __exit__(self, *_):\n",
    "        # Re-assign the real stdout/stderr back to (1) and (2)\n",
    "        os.dup2(self.save_fds[0], 1)\n",
    "        os.dup2(self.save_fds[1], 2)\n",
    "        # Close the null files\n",
    "        os.close(self.null_fds[0])\n",
    "        os.close(self.null_fds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85aee8",
   "metadata": {},
   "source": [
    "## class for reference property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9955fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceProperty():\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        area:str,\n",
    "        latitude: float, \n",
    "        longitude: float, \n",
    "        property_type: str, \n",
    "        target_time: str, \n",
    "        target_feature: str, \n",
    "        training_months: int,\n",
    "        prediction_months: int,\n",
    "        nbedrooms: int = None, \n",
    "        nrooms: int = None, \n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialisation\n",
    "        \"\"\"\n",
    "        \n",
    "        # input information regarding the reference property\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.property_type = property_type\n",
    "        # both bedrooms and rooms (ie, number of habitable rooms is supported)\n",
    "        self.nbedrooms = nbedrooms        \n",
    "        self.nrooms = nrooms\n",
    "        # final data for training\n",
    "        self.target_time = pd.to_datetime(target_time)\n",
    "        # target feature on which the time series is built (usually price)\n",
    "        self.target_feature = target_feature\n",
    "        # how many months to train on\n",
    "        self.training_months = training_months\n",
    "        # how much in the future to predict\n",
    "        self.prediction_months = prediction_months\n",
    "        # how far away from the central hexagon to look at\n",
    "        self.neighboring_radius = 5\n",
    "        self.area = area\n",
    "        \n",
    "        # variable used to store the output\n",
    "        # value of target variable at target time\n",
    "        self.target_mean = None\n",
    "        # std of target variable at target time\n",
    "        self.target_dev = None\n",
    "        # sample of properties in the area at target time\n",
    "        self.sample = None\n",
    "        # time series of values and stds\n",
    "        self.target_ts = None\n",
    "        \n",
    "        # value of target variable at target time\n",
    "        self.target_means = []\n",
    "        # std of target variable at target time\n",
    "        self.target_devs = []\n",
    "        # sample of properties in the area at target time\n",
    "        self.samples = []\n",
    "        # time series of values and stds\n",
    "        self.target_tss = []\n",
    "    \n",
    "    def compute_sales_ts(self, sales: pd.DataFrame):\n",
    "        \n",
    "        \"\"\"\n",
    "        Method to compute the time series of target value\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute distance to ref index and define a weight which inversly proportional to the distance from the reference coordinates\n",
    "        sales[f\"hex_{self.resolution}_distance\"] = 1./(sales[f\"hex_{self.resolution}\"].apply(lambda x: 2*h3.h3_distance(x, self.h3_index))+1)\n",
    "        # sales[f\"hex_{self.resolution}_distance\"] = 1.\n",
    "        \n",
    "        # time series of target\n",
    "        # output initialisation\n",
    "        target_ts = []\n",
    "        target_ts_vals = []\n",
    "        target_ts_stds = []\n",
    "        sample = None\n",
    "        target_mean = None\n",
    "        target_std = None\n",
    "        \n",
    "        # looping on months to build time series\n",
    "        for idx, month in enumerate(list(range(-self.training_months, self.prediction_months))):\n",
    "            \n",
    "            # rolling period of time\n",
    "            time = pd.to_datetime(self.target_time + relativedelta(months=+month))\n",
    "            time_m = pd.to_datetime(time - relativedelta(months=+6))\n",
    "            \n",
    "            # select sales in the given period\n",
    "            sales1 = sales.loc[\n",
    "                (sales[\"date\"]<=time)\n",
    "                &(sales[\"date\"]>=time_m)\n",
    "            ]\n",
    "            \n",
    "            # return if no sales and we are in the training period\n",
    "            if len(sales1)<5 and month<=0:\n",
    "                return None, None, None, None\n",
    "            # removing outliers (THIS SHOULD BE DONE IN A BETTER WAY, AT THE MOMENT EVERYTHING ABOVE 2 SIGMA IS REMOVED)\n",
    "            mean_s = (sales1[f\"hex_{self.resolution}_distance\"]*sales1[self.target_feature]).sum()/(sales1[f\"hex_{self.resolution}_distance\"].sum()+0.001)\n",
    "            std_s = ((sales1[f\"hex_{self.resolution}_distance\"]*((sales1[self.target_feature] - mean_s)**2)).sum()/(sales1[f\"hex_{self.resolution}_distance\"].sum()+0.001))**0.5\n",
    "            sales1 = sales1.loc[\n",
    "                abs(sales1[self.target_feature]-mean_s)<2*std_s\n",
    "            ]\n",
    "            \n",
    "            # return if no sales and we are in the training period\n",
    "            if len(sales1)<5 and month<=0:\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # recompute adjusted mean and stds\n",
    "            mean_s = (sales1[f\"hex_{self.resolution}_distance\"]*sales1[self.target_feature]).sum()/(sales1[f\"hex_{self.resolution}_distance\"].sum()+0.001)\n",
    "            std_s = ((sales1[f\"hex_{self.resolution}_distance\"]*((sales1[self.target_feature] - mean_s)**2)).sum()/(sales1[f\"hex_{self.resolution}_distance\"].sum()+0.001))**0.5\n",
    "            target_ts.append({\"start\":time_m,\"end\":time})\n",
    "            \n",
    "            # save weighted avg and std\n",
    "            target_ts_vals.append(mean_s)\n",
    "            target_ts_stds.append(std_s)\n",
    "            \n",
    "            # month 0 is current date so we save it separatly\n",
    "            if month==0:\n",
    "                target_mean = mean_s\n",
    "                target_std = std_s\n",
    "                sample = sales1\n",
    "        \n",
    "        # append to output the relative index of values\n",
    "        for i,t in enumerate(target_ts):\n",
    "            target_ts[i].update({\"value\": target_ts_vals[i]/target_mean})\n",
    "            target_ts[i].update({\"value_std\": target_ts_stds[i]/target_mean})\n",
    "        \n",
    "        # creating output dataframe\n",
    "        target_ts = pd.DataFrame(target_ts)\n",
    "        target_ts = target_ts.sort_values(\"start\")\n",
    "                \n",
    "        return sample, target_mean, target_std, target_ts\n",
    "\n",
    "    def fit(\n",
    "        self, \n",
    "        sales_listings: pd.DataFrame, \n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Method to create the reference property given coordinates and transactions\n",
    "        \"\"\"\n",
    "        radius_upper_bound = 25\n",
    "        resolutions = [10, 9, 8]\n",
    "        lt_prices_residuals_abs=[]\n",
    "        samples=[]\n",
    "        target_means=[]\n",
    "        target_devs=[]\n",
    "        target_tss = []\n",
    "        while (self.neighboring_radius < radius_upper_bound):\n",
    "            # define which resolution to use\n",
    "            for i in range (0, 3):\n",
    "                # define area filter usage\n",
    "                for j in range (0,2):\n",
    "                    self.resolution = resolutions[i]\n",
    "                    # compute the index of the reference property given the resolution\n",
    "                    self.h3_index = h3.geo_to_h3(lat=self.latitude, lng=self.longitude, resolution=self.resolution)\n",
    "                    # compute the neighboring indices\n",
    "                    self.neighboring_indices = h3.k_ring(self.h3_index,self.neighboring_radius)\n",
    "\n",
    "                    # filter out given the parameters above\n",
    "                    if self.nbedrooms:\n",
    "                        sales_listing_copy = sales_listings.loc[\n",
    "                                (sales_listings[\"bedrooms\"]==self.nbedrooms)\n",
    "                                &(sales_listings[\"property_type\"]==self.property_type)\n",
    "                                &(sales_listings[self.target_feature]>0)\n",
    "                                &(sales_listings[f\"hex_{self.resolution}\"].isin(self.neighboring_indices))\n",
    "                                &((j==0)|(sales_listings[\"area\"]==self.area))\n",
    "                        ]\n",
    "                    else:\n",
    "                        sales_listing_copy = sales_listings.loc[\n",
    "                                (sales_listings[\"rooms\"]==self.nrooms)\n",
    "                                &(sales_listings[\"property_type\"]==self.property_type)\n",
    "                                &(sales_listings[self.target_feature]>0)\n",
    "                                &(sales_listings[f\"hex_{self.resolution}\"].isin(self.neighboring_indices))\n",
    "                                &((j==0)|(sales_listings[\"area\"]==self.area))\n",
    "                        ]\n",
    "\n",
    "                    # compute time series for target variable \n",
    "                    self.sample, self.target_mean, self.target_dev, self.target_ts =  self.compute_sales_ts(sales_listing_copy)\n",
    "                    if self.sample is not None:\n",
    "                        self.samples.append(self.sample)\n",
    "                        self.target_means.append(self.target_mean)\n",
    "                        self.target_devs.append(self.target_dev)\n",
    "                        self.target_tss.append(self.target_ts)\n",
    "\n",
    "            \n",
    "            self.neighboring_radius *=1.5\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "418a01b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]<ipython-input-286-ad2c8f0652a6>:147: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  e24 = (\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [01:56<01:56, 116.38s/it]<ipython-input-286-ad2c8f0652a6>:147: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  e24 = (\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [02:58<00:00, 89.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# looping over all  properties\n",
    "ref_props = []\n",
    "\n",
    "for idx,row in tqdm(merged_df.iterrows(),total=len(merged_df)):\n",
    "    # define what to look for\n",
    "    LATITUDE = row[\"latitude\"]\n",
    "    LONGITUDE = row[\"longitude\"]\n",
    "    BEDROOMS = row[\"pred\"]    \n",
    "    PROPTYPE = row[\"property_type\"]\n",
    "    TARGET_FEATURE = \"price\"\n",
    "    UPRN = row[\"uprn\"]\n",
    "    AREA = row[\"area_code\"]\n",
    "    lt_date = str(row[\"last_transaction_date\"])\n",
    "    lt_price = row[\"last_transaction_price\"]\n",
    "#     print(UPRN)\n",
    "#     break\n",
    "    # initialise class\n",
    "    ref_prop = ReferenceProperty(\n",
    "        area = AREA,\n",
    "        latitude=LATITUDE, \n",
    "        longitude=LONGITUDE,\n",
    "        property_type=PROPTYPE, \n",
    "        target_time=TARGET_TIME, \n",
    "        target_feature=TARGET_FEATURE, \n",
    "        training_months=TRAINING_MONTHS,\n",
    "        prediction_months=PREDICTION_MONTHS,\n",
    "        nbedrooms=BEDROOMS\n",
    "#         nrooms=BEDROOMS,\n",
    "    )\n",
    "\n",
    "    # fit reference property\n",
    "    ref_prop.fit(\n",
    "        sales_listings=source_price_asked\n",
    "    )\n",
    "\n",
    "    # fit prophet model\n",
    "    # resample dates to days\n",
    "    if ref_prop.sample is None:\n",
    "        ref_prop.forecast = None\n",
    "        ref_props.append({\"uprn\": UPRN ,\"rooms\": BEDROOMS, \"type\": PROPTYPE, \"latitude\": LATITUDE, \"longitude\": LONGITUDE,  \"ref\": deepcopy(ref_prop), \"lt_date\": row[\"last_transaction_date\"], \"lt_price\": row[\"last_transaction_price\"], \"pidx\": idx})\n",
    "    else:\n",
    "        lt_prices_residuals = []\n",
    "        for i in range (0, len(ref_prop.target_means)):\n",
    "            tmp = ref_prop.target_ts.copy()\n",
    "\n",
    "            # fill missing values with noisy entries with appropriate std dev\n",
    "            date_range = pd.DataFrame(\n",
    "                {'ds': tmp.loc[tmp[\"end\"]<=ref_prop.target_time, \"end\"], \"y\": tmp.loc[tmp[\"end\"]<=ref_prop.target_time, \"value\"]}\n",
    "            )\n",
    "\n",
    "            # create prophet model\n",
    "            m = Prophet(\n",
    "                yearly_seasonality=True,\n",
    "                weekly_seasonality=False,\n",
    "                daily_seasonality=False,\n",
    "            )\n",
    "            with suppress_stdout_stderr():\n",
    "                m.fit(date_range)\n",
    "\n",
    "            future = pd.DataFrame({'ds': pd.date_range(\n",
    "                tmp.loc[tmp[\"end\"]<=ref_prop.target_time, \"end\"].min(), \n",
    "                periods=TRAINING_MONTHS+PREDICTION_MONTHS+1, freq='M'\n",
    "            ).date+relativedelta(days=+1)})\n",
    "            forecast = m.predict(future)\n",
    "            ltpi = forecast.loc[(forecast[\"ds\"]<pd.to_datetime(lt_date)+relativedelta(months=+1))&(forecast[\"ds\"]>=pd.to_datetime(lt_date)), \"yhat\"].iloc[0]\n",
    "            ltpp = ref_prop.target_means[i]*ltpi\n",
    "            ltpprp = round((ltpp-lt_price)/lt_price,3)\n",
    "            lt_prices_residuals.append(ltpprp)\n",
    "        lt_prices_residuals = np.abs(lt_prices_residuals)\n",
    "        min_value = min(lt_prices_residuals)\n",
    "        min_index=np.where(lt_prices_residuals == min_value)[0][0]\n",
    "        ref_prop.sample = ref_prop.samples[min_index]\n",
    "        ref_prop.target_mean = ref_prop.target_means[min_index]\n",
    "        ref_prop.target_dev = ref_prop.target_devs[min_index]\n",
    "        ref_prop.target_ts = ref_prop.target_tss[min_index]\n",
    "        \n",
    "        \n",
    "        \n",
    "        tmp = ref_prop.target_ts.copy()\n",
    "\n",
    "        # fill missing values with noisy entries with appropriate std dev\n",
    "        date_range = pd.DataFrame(\n",
    "            {'ds': tmp.loc[tmp[\"end\"]<=ref_prop.target_time, \"end\"], \"y\": tmp.loc[tmp[\"end\"]<=ref_prop.target_time, \"value\"]}\n",
    "        )\n",
    "\n",
    "        # create prophet model\n",
    "        m = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "        )\n",
    "        with suppress_stdout_stderr():\n",
    "            m.fit(date_range)\n",
    "\n",
    "        future = pd.DataFrame({'ds': pd.date_range(\n",
    "            tmp.loc[tmp[\"end\"]<=ref_prop.target_time, \"end\"].min(), \n",
    "            periods=TRAINING_MONTHS+PREDICTION_MONTHS+1, freq='M'\n",
    "        ).date+relativedelta(days=+1)})\n",
    "        forecast = m.predict(future)\n",
    "        forecast[\"yhat_upper_std\"] = forecast[\"yhat\"] + ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value_std\"].iloc[0]\n",
    "        forecast[\"yhat_lower_std\"] = forecast[\"yhat\"] - ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value_std\"].iloc[0]\n",
    "        forecast[\"yhat_upper_total\"] = forecast[\"yhat\"] + np.sqrt((forecast[\"yhat_upper\"]-forecast[\"yhat\"])**2 + ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value_std\"].iloc[0]**2)\n",
    "        forecast[\"yhat_lower_total\"] = forecast[\"yhat\"] - np.sqrt((forecast[\"yhat_lower\"]-forecast[\"yhat\"])**2 + ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value_std\"].iloc[0]**2)  \n",
    "        with suppress_stdout_stderr():\n",
    "        \n",
    "            # compute metrics at 0, 12 and 24 months\n",
    "            ap0 = ref_prop.target_mean*ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value\"].iloc[0] \n",
    "            ai0 = ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value\"].iloc[0] \n",
    "            pi0 = forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat\"].iloc[0] \n",
    "            pi0e = forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat_upper\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat\"].iloc[0] \n",
    "            pi0s = forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat_upper_std\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat\"].iloc[0] \n",
    "            pi0t = forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat_upper_total\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat\"].iloc[0] \n",
    "            pp0 = ref_prop.target_mean*pi0\n",
    "            pp0e = ref_prop.target_mean*pi0e\n",
    "            pp0s = ref_prop.target_mean*pi0s\n",
    "            pp0t = ref_prop.target_mean*pi0t\n",
    "            e0 = (\n",
    "                forecast.loc[forecast[\"ds\"]==TARGET_TIME, \"yhat\"].iloc[0] \n",
    "                - ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value\"].iloc[0]\n",
    "            )/ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME, \"value\"].iloc[0]\n",
    "\n",
    "            ap12 = ref_prop.target_mean*ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_12m, \"value\"].iloc[0] \n",
    "            ai12 = ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_12m, \"value\"].iloc[0] \n",
    "            pi12 = forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat\"].iloc[0] \n",
    "            pi12e = forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat_upper\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat\"].iloc[0]\n",
    "            pi12s = forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat_upper_std\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat\"].iloc[0] \n",
    "            pi12t = forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat_upper_total\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat\"].iloc[0]\n",
    "            pp12 = ref_prop.target_mean*pi12\n",
    "            pp12e = ref_prop.target_mean*pi12e\n",
    "            pp12s = ref_prop.target_mean*pi12s\n",
    "            pp12t = ref_prop.target_mean*pi12t\n",
    "            e12 = (\n",
    "                forecast.loc[forecast[\"ds\"]==TARGET_TIME_12m, \"yhat\"].iloc[0] \n",
    "                - ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_12m, \"value\"].iloc[0]\n",
    "            )/ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_12m, \"value\"].iloc[0]\n",
    "\n",
    "            ap24 = ref_prop.target_mean*ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_24m, \"value\"].iloc[0] \n",
    "            ai24 = ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_24m, \"value\"].iloc[0] \n",
    "            pi24 = forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat\"].iloc[0] \n",
    "            pi24e = forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat_upper\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat\"].iloc[0]\n",
    "            pi24s = forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat_upper_std\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat\"].iloc[0] \n",
    "            pi24t = forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat_upper_total\"].iloc[0] - forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat\"].iloc[0]\n",
    "            pp24 = ref_prop.target_mean*pi24\n",
    "            pp24e = ref_prop.target_mean*pi24e\n",
    "            pp24s = ref_prop.target_mean*pi24s\n",
    "            pp24t = ref_prop.target_mean*pi24t\n",
    "            e24 = (\n",
    "                forecast.loc[forecast[\"ds\"]==TARGET_TIME_24m, \"yhat\"].iloc[0] \n",
    "                - ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_24m, \"value\"].iloc[0]\n",
    "            )/ref_prop.target_ts.loc[ref_prop.target_ts[\"end\"]==TARGET_TIME_24m, \"value\"].iloc[0]\n",
    "\n",
    "            try:\n",
    "                ltpi = forecast.loc[(forecast[\"ds\"]<pd.to_datetime(row[\"last_transaction_date\"])+relativedelta(months=+1))&(forecast[\"ds\"]>=pd.to_datetime(row[\"last_transaction_date\"])), \"yhat\"].iloc[0]\n",
    "                ltpie = forecast.loc[(forecast[\"ds\"]<pd.to_datetime(row[\"last_transaction_date\"])+relativedelta(months=+1))&(forecast[\"ds\"]>=pd.to_datetime(row[\"last_transaction_date\"])), \"yhat_upper\"].iloc[0]-ltpi\n",
    "                ltpis = forecast.loc[(forecast[\"ds\"]<pd.to_datetime(row[\"last_transaction_date\"])+relativedelta(months=+1))&(forecast[\"ds\"]>=pd.to_datetime(row[\"last_transaction_date\"])), \"yhat_upper_std\"].iloc[0]-ltpi\n",
    "                ltpit = forecast.loc[(forecast[\"ds\"]<pd.to_datetime(row[\"last_transaction_date\"])+relativedelta(months=+1))&(forecast[\"ds\"]>=pd.to_datetime(row[\"last_transaction_date\"])), \"yhat_upper_total\"].iloc[0]-ltpi\n",
    "                ltpp = ref_prop.target_mean*ltpi\n",
    "                ltppe = ref_prop.target_mean*ltpie\n",
    "                ltpps = ref_prop.target_mean*ltpis\n",
    "                ltppt = ref_prop.target_mean*ltpit\n",
    "            except:\n",
    "                ltpi = np.nan\n",
    "                ltpie = np.nan\n",
    "                ltpis = np.nan\n",
    "                ltpit = np.nan\n",
    "                ltpp = np.nan\n",
    "                ltppe = np.nan\n",
    "                ltpps = np.nan\n",
    "                ltppt = np.nan\n",
    "\n",
    "            # saving values\n",
    "            merged_df.loc[idx, \"sample_size\"] = len(ref_prop.sample)\n",
    "            merged_df.loc[idx, \"last_transaction_predicted_price\"] = round(ltpp,3)\n",
    "            merged_df.loc[idx, \"last_transaction_index\"] = round(row[\"last_transaction_price\"]/ap0,3)\n",
    "            merged_df.loc[idx, \"last_transaction_predicted_price_model_error\"] = round(ltppe,3)\n",
    "            merged_df.loc[idx, \"last_transaction_predicted_price_total_error\"] = round(ltppt,3)\n",
    "            merged_df.loc[idx, \"last_transaction_predicted_price_residual_percentage\"] = round((ltpp-row[\"last_transaction_price\"])/row[\"last_transaction_price\"],3)\n",
    "\n",
    "\n",
    "            ref_prop.forecast = forecast\n",
    "            ref_props.append({\"uprn\": UPRN ,\"rooms\": BEDROOMS, \"type\": PROPTYPE, \"latitude\": LATITUDE, \"longitude\": LONGITUDE,  \"ref\": deepcopy(ref_prop), \"lt_date\": row[\"last_transaction_date\"], \"lt_price\": row[\"last_transaction_price\"], \"pidx\": idx})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c78d4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 500)\n",
    "# # # merged_df\n",
    "# merged_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "feef4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_props_new = []\n",
    "for i,p in enumerate(ref_props):\n",
    "    forecast_dict={}\n",
    "    normalized_forecast ={}\n",
    "    target_ts_dict={}\n",
    "    normalized_target_ts ={}\n",
    "    ref_prop = p[\"ref\"]\n",
    "    if ref_prop.forecast is None:\n",
    "        forecast = ref_prop.forecast\n",
    "    else:\n",
    "        for index, row in forecast.iterrows():\n",
    "            forecast_dict[str(row[\"ds\"].date())]=target_mean *row[\"yhat\"]\n",
    "#         normalized = (x-min(forecast_dict.values()))/(min(forecast_dict.values())-min(forecast_dict.values()))\n",
    "        for key, value in forecast_dict.items():\n",
    "            normalized_forecast[key] =(value-min(forecast_dict.values()))/(max(forecast_dict.values())-min(forecast_dict.values()))\n",
    "    if ref_prop.target_ts is None:\n",
    "        target_ts = ref_prop.target_ts\n",
    "    else: \n",
    "        for index, row in target_ts.iterrows():\n",
    "            target_ts_dict[str(row[\"end\"].date())]=target_mean *row[\"value\"]\n",
    "        for key, value in target_ts_dict.items():\n",
    "            normalized_target_ts[key] =(value-min(target_ts_dict.values()))/(max(target_ts_dict.values())-min(target_ts_dict.values()))\n",
    "    \n",
    "    if  ref_prop.forecast is not None and ref_prop.target_ts is not None : \n",
    "        ref_props_new.append({\"uprn\":p[\"uprn\"] ,\"target_mean\": ref_prop.target_mean,\"target_time\" : ref_prop.target_time,\"target_ts\" : target_ts_dict,\"normalized_target_ts\" : normalized_target_ts,\"forecast\": forecast_dict,\"normalized_forecast\": normalized_forecast,\"number_of_bedrooms\": p[\"rooms\"] , \"type\": p[\"type\"], \"latitude\": p[\"latitude\"], \"longitude\": p[\"longitude\"], \"lt_date\": p[\"lt_date\"], \"lt_price\": p[\"lt_price\"], \"pidx\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0f5682a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.merge(merged_df, pd.DataFrame(ref_props_new) , how='inner',left_on=['uprn','property_type', 'pred', 'last_transaction_price', 'last_transaction_date' ] ,right_on=['uprn','type', 'number_of_bedrooms', 'lt_price', 'lt_date' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "56184c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_columns = [\"uprn\",\"property_type\", 'pred', 'area_code', 'district_code','last_transaction_price','last_transaction_date',\"target_ts\",\"forecast\",\"normalized_target_ts\",\"normalized_forecast\"]\n",
    "output = output[result_columns]\n",
    "output = output.rename(columns={'pred': 'number_of_bedrooms'})\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33596fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
